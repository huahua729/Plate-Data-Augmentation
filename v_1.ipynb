{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3611dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ed9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0401fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = './vision/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebe50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63a047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGenerator = ImageDataGenerator(\n",
    "    rotation_range=90, # 회전각도 \n",
    "    horizontal_flip=True,  # 이미지 뒤집기 \n",
    "    preprocessing_function = get_random_eraser(v_l=0, v_h=255), # 전체 부분의 일부를 가림 \n",
    "    validation_split=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7adc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1028 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'training_set'),\n",
    "    target_size=(100, 100),\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2770a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validationGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'training_set'),\n",
    "    target_size=(100, 100),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10639f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 3)                 23593859  \n",
      "=================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top=True, weights=None, input_shape=(100, 100, 3), classes=3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3306c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccdb57a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-59f28718cd00>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002EAB799B7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002EAB799B7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "21/20 [==============================] - ETA: 0s - loss: 1.2214 - acc: 0.6134WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002ED5FD7E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002ED5FD7E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20.56 batches). You may need to use the repeat() function when building your dataset.\n",
      "21/20 [==============================] - 5s 219ms/step - loss: 1.2214 - acc: 0.6134 - val_loss: 3.5547 - val_acc: 0.6523\n",
      "Epoch 2/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.5778 - acc: 0.7515\n",
      "Epoch 3/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.2643 - acc: 0.8155\n",
      "Epoch 4/50\n",
      "21/20 [==============================] - 3s 128ms/step - loss: 0.2313 - acc: 0.8363\n",
      "Epoch 5/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.2452 - acc: 0.8289\n",
      "Epoch 6/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1846 - acc: 0.8820\n",
      "Epoch 7/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.2564 - acc: 0.8447\n",
      "Epoch 8/50\n",
      "21/20 [==============================] - 3s 121ms/step - loss: 0.1845 - acc: 0.8696\n",
      "Epoch 9/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.2050 - acc: 0.8616\n",
      "Epoch 10/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1821 - acc: 0.8705\n",
      "Epoch 11/50\n",
      "21/20 [==============================] - 3s 121ms/step - loss: 0.2028 - acc: 0.8758\n",
      "Epoch 12/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1879 - acc: 0.8929\n",
      "Epoch 13/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.2455 - acc: 0.8339\n",
      "Epoch 14/50\n",
      "21/20 [==============================] - 3s 123ms/step - loss: 0.1666 - acc: 0.8975\n",
      "Epoch 15/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.2095 - acc: 0.8789\n",
      "Epoch 16/50\n",
      "21/20 [==============================] - 3s 129ms/step - loss: 0.1737 - acc: 0.8975\n",
      "Epoch 17/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1591 - acc: 0.8975\n",
      "Epoch 18/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1628 - acc: 0.9022 1s - loss: 0.1939 -\n",
      "Epoch 19/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.1302 - acc: 0.9270\n",
      "Epoch 20/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1732 - acc: 0.8991\n",
      "Epoch 21/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.2043 - acc: 0.8711\n",
      "Epoch 22/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1584 - acc: 0.9037\n",
      "Epoch 23/50\n",
      "21/20 [==============================] - 3s 131ms/step - loss: 0.2111 - acc: 0.8690\n",
      "Epoch 24/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.1331 - acc: 0.9239\n",
      "Epoch 25/50\n",
      "21/20 [==============================] - 3s 136ms/step - loss: 0.1518 - acc: 0.9053\n",
      "Epoch 26/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.1243 - acc: 0.9208\n",
      "Epoch 27/50\n",
      "21/20 [==============================] - 3s 123ms/step - loss: 0.1062 - acc: 0.9379\n",
      "Epoch 28/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.0908 - acc: 0.9449\n",
      "Epoch 29/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.1018 - acc: 0.9435\n",
      "Epoch 30/50\n",
      "21/20 [==============================] - 3s 123ms/step - loss: 0.1109 - acc: 0.9348\n",
      "Epoch 31/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.1168 - acc: 0.9315\n",
      "Epoch 32/50\n",
      "21/20 [==============================] - 3s 123ms/step - loss: 0.1236 - acc: 0.9301\n",
      "Epoch 33/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1095 - acc: 0.9332\n",
      "Epoch 34/50\n",
      "21/20 [==============================] - 3s 121ms/step - loss: 0.1119 - acc: 0.9301\n",
      "Epoch 35/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1341 - acc: 0.9239\n",
      "Epoch 36/50\n",
      "21/20 [==============================] - 3s 130ms/step - loss: 0.1255 - acc: 0.9211\n",
      "Epoch 37/50\n",
      "21/20 [==============================] - 3s 127ms/step - loss: 0.0993 - acc: 0.9360\n",
      "Epoch 38/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.2178 - acc: 0.8540\n",
      "Epoch 39/50\n",
      "21/20 [==============================] - 3s 124ms/step - loss: 0.1670 - acc: 0.8851\n",
      "Epoch 40/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.1556 - acc: 0.9006\n",
      "Epoch 41/50\n",
      "21/20 [==============================] - 3s 124ms/step - loss: 0.1297 - acc: 0.9177\n",
      "Epoch 42/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.1327 - acc: 0.9241\n",
      "Epoch 43/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1124 - acc: 0.9255\n",
      "Epoch 44/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1113 - acc: 0.9348 1s - loss: 0.1\n",
      "Epoch 45/50\n",
      "21/20 [==============================] - 3s 125ms/step - loss: 0.0922 - acc: 0.9524\n",
      "Epoch 46/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.0749 - acc: 0.9612\n",
      "Epoch 47/50\n",
      "21/20 [==============================] - 3s 123ms/step - loss: 0.1062 - acc: 0.9394\n",
      "Epoch 48/50\n",
      "21/20 [==============================] - 3s 122ms/step - loss: 0.1668 - acc: 0.9130 0s - loss: 0.1874 - ac\n",
      "Epoch 49/50\n",
      "21/20 [==============================] - 3s 126ms/step - loss: 0.1068 - acc: 0.9360\n",
      "Epoch 50/50\n",
      "21/20 [==============================] - 3s 128ms/step - loss: 0.0872 - acc: 0.9441\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = model.fit_generator(\n",
    "    trainGen, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=trainGen.samples / epochs, \n",
    "    validation_data=validationGen,\n",
    "    validation_steps=trainGen.samples / epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bcfb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "testGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'test_set'),\n",
    "    target_size=(100, 100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "075dd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002ED9176EB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002ED9176EB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(testGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d73990",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = testGen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f703af6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['burn_disease\\\\burn1.png',\n",
       " 'burn_disease\\\\burn2.png',\n",
       " 'burn_disease\\\\burn3.png',\n",
       " 'burn_disease\\\\burn4.png',\n",
       " 'burn_disease\\\\burn5.png',\n",
       " 'healthy\\\\hel1.jpg',\n",
       " 'healthy\\\\hel2.jpg',\n",
       " 'healthy\\\\hel3.jpg',\n",
       " 'healthy\\\\hel4.jpg',\n",
       " 'healthy\\\\hel5.jpg',\n",
       " 'leafspot\\\\leafspot1.png',\n",
       " 'leafspot\\\\leafspot2.png',\n",
       " 'leafspot\\\\leafspot3.png',\n",
       " 'leafspot\\\\leafspot4.png',\n",
       " 'leafspot\\\\leafspot5.png']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a126ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(len(pred)):\n",
    "    pred_list.append(np.argmax(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc44950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(img_list, pred_list)), columns =['Name', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d63eef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6d02ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-83d3fb053500>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "정확도 : 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 :\", model.evaluate_generator(testGen)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29eaae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a883b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_tensor)",
   "language": "python",
   "name": "text_tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
